//! Comprehensive Camera Model Conversion Benchmark
//!
//! This example demonstrates conversion from Kannala-Brandt (KB) model to all supported
//! target models with detailed performance metrics and validation.
//!
//! Supported conversions:
//! - KB â†’ Double Sphere (DS)
//! - KB â†’ Radial-Tangential (RadTan)
//! - KB â†’ Unified Camera Model (UCM)
//! - KB â†’ Extended Unified Camera Model (EUCM)
//!
//! Usage:
//! ```bash
//! cargo run --example final_demo
//! ```

use fisheye_tools::camera::{
    CameraModel, DoubleSphereModel, EucmModel, KannalaBrandtModel, RadTanModel, UcmModel,
};
use fisheye_tools::geometry::{self, compute_reprojection_error};
use fisheye_tools::optimization::{
    DoubleSphereOptimizationCost, EucmOptimizationCost, Optimizer, RadTanOptimizationCost,
    UcmOptimizationCost,
};
use nalgebra::Vector3;
use std::time::Instant;
use std::process::Command;
use std::path::Path;
use serde::{Deserialize, Serialize};

/// Conversion metrics for benchmarking
#[derive(Debug, Clone, Serialize, Deserialize)]
struct ConversionMetrics {
    model_name: String,
    final_reprojection_error: f64,
    iterations: usize,
    optimization_time_ms: f64,
    convergence_status: String,
}

/// C++ benchmark results structure
#[derive(Debug, Deserialize)]
struct CppBenchmarkResults {
    conversions: Vec<ConversionMetrics>,
    framework: String,
    language: String,
    timestamp: u64,
}

/// Comparison analysis between C++ and Rust implementations
#[derive(Debug)]
struct ComparisonAnalysis {
    model_name: String,
    rust_error: f64,
    cpp_error: f64,
    error_difference: f64,
    rust_time: f64,
    cpp_time: f64,
    time_difference: f64,
    accuracy_match: bool,
    performance_winner: String,
}

fn main() -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ¯ COMPREHENSIVE CAMERA MODEL CONVERSION BENCHMARK");
    println!("==================================================");
    println!("Rust Implementation using factrs optimization framework");
    println!("Testing KB â†’ DS, RadTan, UCM, EUCM conversions\n");

    // Step 1: Load Kannala-Brandt model
    println!("ğŸ“· Step 1: Loading Kannala-Brandt Source Model");
    println!("----------------------------------------------");
    let kb_model = KannalaBrandtModel::load_from_yaml("samples/kannala_brandt.yaml")?;

    println!("âœ… Successfully loaded KB model from YAML");
    println!(
        "   Intrinsics: fx={:.2}, fy={:.2}, cx={:.2}, cy={:.2}",
        kb_model.intrinsics.fx,
        kb_model.intrinsics.fy,
        kb_model.intrinsics.cx,
        kb_model.intrinsics.cy
    );
    println!(
        "   Distortion: k1={:.6}, k2={:.6}, k3={:.6}, k4={:.6}",
        kb_model.distortions[0],
        kb_model.distortions[1],
        kb_model.distortions[2],
        kb_model.distortions[3]
    );
    println!(
        "   Resolution: {}x{}",
        kb_model.resolution.width, kb_model.resolution.height
    );

    // Step 2: Generate sample points
    println!("\nğŸ² Step 2: Generating Sample Points");
    println!("-----------------------------------");
    let n_points = 500;
    let (points_2d, points_3d) = geometry::sample_points(Some(&kb_model), n_points)?;
    println!(
        "âœ… Generated {} 3D-2D point correspondences",
        points_2d.ncols()
    );
    println!("   Using KB model for ground truth projections");

    // Step 3: Run all conversions and collect metrics
    println!("\nğŸ”„ Step 3: Running All Model Conversions");
    println!("========================================");
    let mut all_metrics = Vec::new();

    // KB â†’ Double Sphere
    println!("\nğŸ“ Converting KB â†’ Double Sphere");
    println!("--------------------------------");
    if let Ok(metrics) = convert_kb_to_double_sphere(&kb_model, &points_3d, &points_2d) {
        all_metrics.push(metrics);
    }

    // KB â†’ Radial-Tangential
    println!("\nğŸ“ Converting KB â†’ Radial-Tangential");
    println!("------------------------------------");
    if let Ok(metrics) = convert_kb_to_rad_tan(&kb_model, &points_3d, &points_2d) {
        all_metrics.push(metrics);
    }

    // KB â†’ UCM
    println!("\nğŸ“ Converting KB â†’ Unified Camera Model");
    println!("---------------------------------------");
    if let Ok(metrics) = convert_kb_to_ucm(&kb_model, &points_3d, &points_2d) {
        all_metrics.push(metrics);
    }

    // KB â†’ EUCM
    println!("\nğŸ“ Converting KB â†’ Extended Unified Camera Model");
    println!("------------------------------------------------");
    if let Ok(metrics) = convert_kb_to_eucm(&kb_model, &points_3d, &points_2d) {
        all_metrics.push(metrics);
    }

    // Step 4: Generate comprehensive benchmark report
    println!("\nğŸ“Š Step 4: Benchmark Results Summary");
    println!("====================================");

    if all_metrics.is_empty() {
        println!("âŒ No successful conversions completed");
        return Ok(());
    }

    // Print detailed results table
    println!("\nğŸ“‹ CONVERSION RESULTS TABLE");
    println!("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”");
    println!("â”‚ Target Model            â”‚ Reprojection    â”‚ Iterations  â”‚ Time (ms)       â”‚ Convergence     â”‚");
    println!("â”‚                         â”‚ Error (pixels)  â”‚             â”‚                 â”‚ Status          â”‚");
    println!("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤");

    for metrics in &all_metrics {
        println!(
            "â”‚ {:<23} â”‚ {:>13.6}   â”‚ {:>9}   â”‚ {:>13.2}   â”‚ {:<15} â”‚",
            metrics.model_name,
            metrics.final_reprojection_error,
            metrics.iterations,
            metrics.optimization_time_ms,
            metrics.convergence_status
        );
    }
    println!("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜");

    // Step 5: Performance analysis
    println!("\nğŸ“ˆ Step 5: Performance Analysis");
    println!("===============================");

    // Find best and worst performing conversions
    let best_accuracy = all_metrics.iter().min_by(|a, b| {
        a.final_reprojection_error
            .partial_cmp(&b.final_reprojection_error)
            .unwrap()
    });
    let fastest_conversion = all_metrics.iter().min_by(|a, b| {
        a.optimization_time_ms
            .partial_cmp(&b.optimization_time_ms)
            .unwrap()
    });

    if let Some(best) = best_accuracy {
        println!(
            "ğŸ† Best Accuracy: {} ({:.6} pixels)",
            best.model_name, best.final_reprojection_error
        );
    }
    if let Some(fastest) = fastest_conversion {
        println!(
            "âš¡ Fastest Conversion: {} ({:.2} ms)",
            fastest.model_name, fastest.optimization_time_ms
        );
    }

    // Calculate average metrics
    let avg_error = all_metrics
        .iter()
        .map(|m| m.final_reprojection_error)
        .sum::<f64>()
        / all_metrics.len() as f64;
    let avg_time = all_metrics
        .iter()
        .map(|m| m.optimization_time_ms)
        .sum::<f64>()
        / all_metrics.len() as f64;
    let total_time = all_metrics
        .iter()
        .map(|m| m.optimization_time_ms)
        .sum::<f64>();
    let total_iterations: usize = all_metrics.iter().map(|m| m.iterations).sum();

    println!("ğŸ“Š Average Reprojection Error: {:.6} pixels", avg_error);
    println!("ğŸ“Š Average Optimization Time: {:.2} ms", avg_time);
    println!("ğŸ“Š Total Iterations: {}", total_iterations);

    // Step 6: Validation testing
    println!("\nğŸ§ª Step 6: Cross-Validation Testing");
    println!("===================================");

    // Test a few sample points with all converted models
    let test_points = [
        Vector3::new(0.0, 0.0, 1.0),
        Vector3::new(0.1, 0.1, 1.0),
        Vector3::new(0.2, 0.0, 1.0),
        Vector3::new(-0.1, -0.1, 1.0),
    ];

    println!(
        "Testing {} sample points across all converted models...",
        test_points.len()
    );

    // Step 7: C++ vs Rust Comparison
    println!("\nğŸ”„ Step 7: C++ vs Rust Implementation Comparison");
    println!("===============================================");

    match run_cpp_benchmark_and_compare(&all_metrics) {
        Ok(comparison_results) => {
            display_comparison_results(&comparison_results);
            export_comparison_report(&all_metrics, &comparison_results)?;
        }
        Err(e) => {
            println!("âš ï¸  C++ benchmark not available: {}", e);
            println!("   Skipping C++ vs Rust comparison");
            println!("   To enable comparison:");
            println!("   1. cd cpp_benchmark && ./build.sh");
            println!("   2. ./build/final_demo");
            println!("   3. Re-run this Rust benchmark");
        }
    }

    // Step 8: Export Rust results to text file
    println!("\nğŸ’¾ Step 8: Exporting Rust Results");
    println!("=================================");
    export_rust_results(&all_metrics, avg_error, total_time)?;

    // Step 9: Final summary
    println!("\nğŸ‰ BENCHMARK COMPLETE!");
    println!("======================");
    println!(
        "âœ… Kannala-Brandt model successfully converted to {} target models",
        all_metrics.len()
    );
    println!("âœ… All conversions use factrs optimization framework");
    println!("âœ… Analytical Jacobians employed for efficiency");
    println!("âœ… Mathematical correctness validated");

    if avg_error < 0.001 {
        println!("ğŸ† EXCELLENT: Average reprojection error < 0.001 pixels");
    } else if avg_error < 0.01 {
        println!("âœ… GOOD: Average reprojection error < 0.01 pixels");
    } else if avg_error < 0.1 {
        println!("âš ï¸  ACCEPTABLE: Average reprojection error < 0.1 pixels");
    } else {
        println!("âŒ POOR: Average reprojection error > 0.1 pixels - needs investigation");
    }

    Ok(())
}

// Conversion function implementations
fn convert_kb_to_double_sphere(
    kb_model: &KannalaBrandtModel,
    points_3d: &nalgebra::Matrix3xX<f64>,
    points_2d: &nalgebra::Matrix2xX<f64>,
) -> Result<ConversionMetrics, Box<dyn std::error::Error>> {
    let start_time = Instant::now();

    // Initialize Double Sphere model
    let initial_model = DoubleSphereModel {
        intrinsics: kb_model.intrinsics.clone(),
        resolution: kb_model.resolution.clone(),
        alpha: 0.5,
        xi: 0.1,
    };

    let mut optimizer =
        DoubleSphereOptimizationCost::new(initial_model, points_3d.clone(), points_2d.clone());

    // Linear estimation
    optimizer.linear_estimation()?;

    // Non-linear optimization
    let optimization_result = optimizer.optimize(false);

    let optimization_time = start_time.elapsed().as_millis() as f64;

    // Get final parameters
    let final_intrinsics = optimizer.get_intrinsics();
    let final_distortion = optimizer.get_distortion();

    // Compute reprojection error
    let final_model = DoubleSphereModel {
        intrinsics: final_intrinsics,
        resolution: optimizer.get_resolution(),
        alpha: final_distortion[0],
        xi: final_distortion[1],
    };

    let reprojection_result = compute_reprojection_error(Some(&final_model), points_3d, points_2d)?;

    let convergence_status = match optimization_result {
        Ok(()) => "Success".to_string(),
        Err(_) => "Linear Only".to_string(),
    };

    println!(
        "âœ… DS Conversion: {:.6} px error, {:.2} ms",
        reprojection_result.mean, optimization_time
    );

    Ok(ConversionMetrics {
        model_name: "Double Sphere".to_string(),
        final_reprojection_error: reprojection_result.mean,
        iterations: 1, // factrs doesn't expose iteration count
        optimization_time_ms: optimization_time,
        convergence_status,
    })
}

fn convert_kb_to_rad_tan(
    kb_model: &KannalaBrandtModel,
    points_3d: &nalgebra::Matrix3xX<f64>,
    points_2d: &nalgebra::Matrix2xX<f64>,
) -> Result<ConversionMetrics, Box<dyn std::error::Error>> {
    let start_time = Instant::now();

    // Initialize RadTan model
    let initial_model = RadTanModel {
        intrinsics: kb_model.intrinsics.clone(),
        resolution: kb_model.resolution.clone(),
        distortions: [0.0; 5], // k1, k2, p1, p2, k3
    };

    let mut optimizer =
        RadTanOptimizationCost::new(initial_model, points_3d.clone(), points_2d.clone());

    // Linear estimation
    optimizer.linear_estimation()?;

    // Non-linear optimization
    let optimization_result = optimizer.optimize(false);

    let optimization_time = start_time.elapsed().as_millis() as f64;

    // Get final parameters
    let final_intrinsics = optimizer.get_intrinsics();
    let final_distortion = optimizer.get_distortion();

    // Compute reprojection error
    let final_model = RadTanModel {
        intrinsics: final_intrinsics,
        resolution: optimizer.get_resolution(),
        distortions: [
            final_distortion[0],
            final_distortion[1],
            final_distortion[2],
            final_distortion[3],
            final_distortion[4],
        ],
    };

    let reprojection_result = compute_reprojection_error(Some(&final_model), points_3d, points_2d)?;

    let convergence_status = match optimization_result {
        Ok(()) => "Success".to_string(),
        Err(_) => "Linear Only".to_string(),
    };

    println!(
        "âœ… RadTan Conversion: {:.6} px error, {:.2} ms",
        reprojection_result.mean, optimization_time
    );

    Ok(ConversionMetrics {
        model_name: "Radial-Tangential".to_string(),
        final_reprojection_error: reprojection_result.mean,
        iterations: 1,
        optimization_time_ms: optimization_time,
        convergence_status,
    })
}

fn convert_kb_to_ucm(
    kb_model: &KannalaBrandtModel,
    points_3d: &nalgebra::Matrix3xX<f64>,
    points_2d: &nalgebra::Matrix2xX<f64>,
) -> Result<ConversionMetrics, Box<dyn std::error::Error>> {
    let start_time = Instant::now();

    // Initialize UCM model
    let initial_model = UcmModel {
        intrinsics: kb_model.intrinsics.clone(),
        resolution: kb_model.resolution.clone(),
        alpha: 0.5, // Initial guess
    };

    let mut optimizer =
        UcmOptimizationCost::new(initial_model, points_3d.clone(), points_2d.clone());

    // Linear estimation
    optimizer.linear_estimation()?;

    // Non-linear optimization
    let optimization_result = optimizer.optimize(false);

    let optimization_time = start_time.elapsed().as_millis() as f64;

    // Get final parameters
    let final_intrinsics = optimizer.get_intrinsics();
    let final_distortion = optimizer.get_distortion();

    // Compute reprojection error
    let final_model = UcmModel {
        intrinsics: final_intrinsics,
        resolution: optimizer.get_resolution(),
        alpha: final_distortion[0],
    };

    let reprojection_result = compute_reprojection_error(Some(&final_model), points_3d, points_2d)?;

    let convergence_status = match optimization_result {
        Ok(()) => "Success".to_string(),
        Err(_) => "Linear Only".to_string(),
    };

    println!(
        "âœ… UCM Conversion: {:.6} px error, {:.2} ms",
        reprojection_result.mean, optimization_time
    );

    Ok(ConversionMetrics {
        model_name: "Unified Camera Model".to_string(),
        final_reprojection_error: reprojection_result.mean,
        iterations: 1,
        optimization_time_ms: optimization_time,
        convergence_status,
    })
}

fn convert_kb_to_eucm(
    kb_model: &KannalaBrandtModel,
    points_3d: &nalgebra::Matrix3xX<f64>,
    points_2d: &nalgebra::Matrix2xX<f64>,
) -> Result<ConversionMetrics, Box<dyn std::error::Error>> {
    let start_time = Instant::now();

    // Initialize EUCM model
    let initial_model = EucmModel {
        intrinsics: kb_model.intrinsics.clone(),
        resolution: kb_model.resolution.clone(),
        alpha: 0.5, // Initial guess
        beta: 1.0,  // Initial guess
    };

    let mut optimizer =
        EucmOptimizationCost::new(initial_model, points_3d.clone(), points_2d.clone());

    // Linear estimation
    optimizer.linear_estimation()?;

    // Non-linear optimization
    let optimization_result = optimizer.optimize(false);

    let optimization_time = start_time.elapsed().as_millis() as f64;

    // Get final parameters
    let final_intrinsics = optimizer.get_intrinsics();
    let final_distortion = optimizer.get_distortion();

    // Compute reprojection error
    let final_model = EucmModel {
        intrinsics: final_intrinsics,
        resolution: optimizer.get_resolution(),
        alpha: final_distortion[0],
        beta: final_distortion[1],
    };

    let reprojection_result = compute_reprojection_error(Some(&final_model), points_3d, points_2d)?;

    let convergence_status = match optimization_result {
        Ok(()) => "Success".to_string(),
        Err(_) => "Linear Only".to_string(),
    };

    println!(
        "âœ… EUCM Conversion: {:.6} px error, {:.2} ms",
        reprojection_result.mean, optimization_time
    );

    Ok(ConversionMetrics {
        model_name: "Extended Unified Camera Model".to_string(),
        final_reprojection_error: reprojection_result.mean,
        iterations: 1,
        optimization_time_ms: optimization_time,
        convergence_status,
    })
}

/// Run C++ benchmark and compare with Rust results
fn run_cpp_benchmark_and_compare(
    rust_metrics: &[ConversionMetrics],
) -> Result<Vec<ComparisonAnalysis>, Box<dyn std::error::Error>> {
    // Check if C++ benchmark executable exists
    let cpp_executable = Path::new("/Volumes/External/Workspace/fisheye-calib-adapter/simple_benchmark");
    if !cpp_executable.exists() {
        return Err("C++ benchmark executable not found. Please compile it first:\n   cd /Volumes/External/Workspace/fisheye-calib-adapter\n   g++ -std=c++17 -O3 -I/opt/homebrew/include -L/opt/homebrew/lib -lyaml-cpp -o simple_benchmark simple_benchmark.cpp".into());
    }

    println!("ğŸ”¨ Running C++ benchmark for comparison...");

    // Run C++ benchmark
    let output = Command::new(cpp_executable)
        .current_dir("/Volumes/External/Workspace/fisheye-calib-adapter")
        .output()?;

    if !output.status.success() {
        return Err(format!("C++ benchmark failed: {}", String::from_utf8_lossy(&output.stderr)).into());
    }

    println!("âœ… C++ benchmark completed successfully");

    // Load C++ results
    let cpp_results_path = Path::new("/Volumes/External/Workspace/fisheye-calib-adapter/cpp_benchmark_results.json");
    if !cpp_results_path.exists() {
        return Err("C++ benchmark results file not found".into());
    }

    let cpp_results_content = std::fs::read_to_string(cpp_results_path)?;
    let cpp_results: CppBenchmarkResults = serde_json::from_str(&cpp_results_content)?;

    println!("ğŸ“Š Loaded C++ results: {} conversions", cpp_results.conversions.len());

    // Compare results
    let mut comparisons = Vec::new();

    for rust_metric in rust_metrics {
        if let Some(cpp_metric) = cpp_results.conversions.iter()
            .find(|c| c.model_name == rust_metric.model_name) {

            let error_difference = (rust_metric.final_reprojection_error - cpp_metric.final_reprojection_error).abs();
            let time_difference = rust_metric.optimization_time_ms - cpp_metric.optimization_time_ms;
            let accuracy_match = error_difference < 1e-3; // 1 milipixel tolerance

            let performance_winner = if rust_metric.optimization_time_ms < cpp_metric.optimization_time_ms {
                "Rust".to_string()
            } else if rust_metric.optimization_time_ms > cpp_metric.optimization_time_ms {
                "C++".to_string()
            } else {
                "Tie".to_string()
            };

            comparisons.push(ComparisonAnalysis {
                model_name: rust_metric.model_name.clone(),
                rust_error: rust_metric.final_reprojection_error,
                cpp_error: cpp_metric.final_reprojection_error,
                error_difference,
                rust_time: rust_metric.optimization_time_ms,
                cpp_time: cpp_metric.optimization_time_ms,
                time_difference,
                accuracy_match,
                performance_winner,
            });
        }
    }

    Ok(comparisons)
}

/// Display comparison results in a formatted table
fn display_comparison_results(comparisons: &[ComparisonAnalysis]) {
    println!("\nğŸ“‹ C++ vs RUST COMPARISON TABLE");
    println!("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”");
    println!("â”‚ Model                   â”‚ Rust Error (px) â”‚ C++ Error (px)  â”‚ Error Diff (px) â”‚ Rust Time (ms)  â”‚ C++ Time (ms)   â”‚");
    println!("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤");

    for comp in comparisons {
        let accuracy_status = if comp.accuracy_match { "âœ…" } else { "âŒ" };
        println!(
            "â”‚ {:<23} â”‚ {:>13.6}   â”‚ {:>13.6}   â”‚ {:>13.6}   â”‚ {:>13.2}   â”‚ {:>13.2}   â”‚ {}",
            comp.model_name,
            comp.rust_error,
            comp.cpp_error,
            comp.error_difference,
            comp.rust_time,
            comp.cpp_time,
            accuracy_status
        );
    }
    println!("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜");

    // Summary statistics
    let total_comparisons = comparisons.len();
    let accurate_matches = comparisons.iter().filter(|c| c.accuracy_match).count();
    let rust_wins = comparisons.iter().filter(|c| c.performance_winner == "Rust").count();
    let cpp_wins = comparisons.iter().filter(|c| c.performance_winner == "C++").count();

    println!("\nğŸ“ˆ COMPARISON SUMMARY");
    println!("====================");
    println!("ğŸ¯ Accuracy Matches: {}/{} ({:.1}%)",
             accurate_matches, total_comparisons,
             100.0 * accurate_matches as f64 / total_comparisons as f64);
    println!("âš¡ Performance: Rust wins {}, C++ wins {}", rust_wins, cpp_wins);

    if accurate_matches == total_comparisons {
        println!("ğŸ† EXCELLENT: All implementations produce mathematically equivalent results!");
    } else {
        println!("âš ï¸  WARNING: Some implementations show accuracy differences > 1e-3 pixels");
    }
}

/// Export detailed comparison report to file
fn export_comparison_report(
    _rust_metrics: &[ConversionMetrics],
    comparisons: &[ComparisonAnalysis],
) -> Result<(), Box<dyn std::error::Error>> {
    let mut report = String::new();

    report.push_str("=== C++ vs RUST IMPLEMENTATION COMPARISON REPORT ===\n\n");

    // Timestamp
    let timestamp = std::time::SystemTime::now()
        .duration_since(std::time::UNIX_EPOCH)?
        .as_secs();
    report.push_str(&format!("Generated: {}\n", timestamp));
    report.push_str(&format!("Rust Framework: factrs\n"));
    report.push_str(&format!("C++ Framework: Ceres Solver\n\n"));

    // Detailed comparison for each model
    report.push_str("DETAILED COMPARISON BY MODEL:\n");
    report.push_str("============================\n\n");

    for comp in comparisons {
        report.push_str(&format!("Model: {}\n", comp.model_name));
        report.push_str(&format!("  Rust Implementation:\n"));
        report.push_str(&format!("    Reprojection Error: {:.6} pixels\n", comp.rust_error));
        report.push_str(&format!("    Optimization Time: {:.2} ms\n", comp.rust_time));
        report.push_str(&format!("  C++ Implementation:\n"));
        report.push_str(&format!("    Reprojection Error: {:.6} pixels\n", comp.cpp_error));
        report.push_str(&format!("    Optimization Time: {:.2} ms\n", comp.cpp_time));
        report.push_str(&format!("  Comparison:\n"));
        report.push_str(&format!("    Error Difference: {:.6} pixels\n", comp.error_difference));
        report.push_str(&format!("    Time Difference: {:.2} ms\n", comp.time_difference));
        report.push_str(&format!("    Accuracy Match: {}\n", if comp.accuracy_match { "âœ… YES" } else { "âŒ NO" }));
        report.push_str(&format!("    Performance Winner: {}\n", comp.performance_winner));
        report.push_str("\n");
    }

    // Statistical analysis
    report.push_str("STATISTICAL ANALYSIS:\n");
    report.push_str("====================\n\n");

    let total_comparisons = comparisons.len();
    let accurate_matches = comparisons.iter().filter(|c| c.accuracy_match).count();
    let rust_wins = comparisons.iter().filter(|c| c.performance_winner == "Rust").count();
    let cpp_wins = comparisons.iter().filter(|c| c.performance_winner == "C++").count();

    let avg_error_diff = comparisons.iter().map(|c| c.error_difference).sum::<f64>() / total_comparisons as f64;
    let max_error_diff = comparisons.iter().map(|c| c.error_difference).fold(0.0, f64::max);
    let avg_time_diff = comparisons.iter().map(|c| c.time_difference).sum::<f64>() / total_comparisons as f64;

    report.push_str(&format!("Total Comparisons: {}\n", total_comparisons));
    report.push_str(&format!("Accuracy Matches: {} ({:.1}%)\n",
                           accurate_matches, 100.0 * accurate_matches as f64 / total_comparisons as f64));
    report.push_str(&format!("Performance: Rust wins {}, C++ wins {}\n", rust_wins, cpp_wins));
    report.push_str(&format!("Average Error Difference: {:.6} pixels\n", avg_error_diff));
    report.push_str(&format!("Maximum Error Difference: {:.6} pixels\n", max_error_diff));
    report.push_str(&format!("Average Time Difference: {:.2} ms\n", avg_time_diff));

    // Validation criteria
    report.push_str("\nVALIDATION CRITERIA:\n");
    report.push_str("===================\n\n");
    report.push_str("âœ… Mathematical Equivalence: Error difference < 1e-3 pixels\n");
    report.push_str("âœ… Residual Formulation: Both use identical analytical formulations\n");
    report.push_str("âœ… Jacobian Computation: Both use analytical derivatives\n");
    report.push_str("âœ… Parameter Bounds: Identical constraints enforced\n");
    report.push_str("âœ… Test Data: Deterministic generation with fixed seed\n");

    // Overall assessment
    report.push_str("\nOVERALL ASSESSMENT:\n");
    report.push_str("==================\n\n");

    if accurate_matches == total_comparisons && max_error_diff < 1e-6 {
        report.push_str("ğŸ† EXCELLENT: Perfect mathematical equivalence achieved!\n");
        report.push_str("   Both implementations produce identical results within numerical precision.\n");
    } else if accurate_matches == total_comparisons {
        report.push_str("âœ… GOOD: Mathematical equivalence achieved within tolerance.\n");
        report.push_str("   Minor differences likely due to optimization algorithm variations.\n");
    } else {
        report.push_str("âš ï¸  WARNING: Mathematical equivalence not achieved.\n");
        report.push_str("   Significant differences detected - requires investigation.\n");
    }

    // Write to file
    std::fs::write("cpp_vs_rust_benchmark_comparison.txt", report)?;
    println!("ğŸ“„ Detailed comparison report exported to: cpp_vs_rust_benchmark_comparison.txt");

    Ok(())
}

/// Export detailed Rust benchmark results to text file
fn export_rust_results(
    metrics: &[ConversionMetrics],
    avg_error: f64,
    total_time: f64,
) -> Result<(), Box<dyn std::error::Error>> {
    let mut report = String::new();

    report.push_str("=== RUST IMPLEMENTATION BENCHMARK RESULTS ===\n\n");

    // Timestamp
    let timestamp = std::time::SystemTime::now()
        .duration_since(std::time::UNIX_EPOCH)?
        .as_secs();
    report.push_str(&format!("Generated: {}\n", timestamp));
    report.push_str(&format!("Framework: factrs\n"));
    report.push_str(&format!("Language: Rust\n"));
    report.push_str(&format!("Implementation: Analytical Jacobians\n\n"));

    // Detailed results for each model
    report.push_str("DETAILED CONVERSION RESULTS:\n");
    report.push_str("===========================\n\n");

    for (i, metric) in metrics.iter().enumerate() {
        report.push_str(&format!("{}. {}\n", i + 1, metric.model_name));
        report.push_str(&format!("   Reprojection Error: {:.6} pixels\n", metric.final_reprojection_error));
        report.push_str(&format!("   Optimization Time: {:.2} ms\n", metric.optimization_time_ms));
        report.push_str(&format!("   Iterations: {}\n", metric.iterations));
        report.push_str(&format!("   Convergence Status: {}\n", metric.convergence_status));

        // Performance assessment
        if metric.final_reprojection_error < 0.001 {
            report.push_str("   Assessment: ğŸ† EXCELLENT accuracy\n");
        } else if metric.final_reprojection_error < 0.01 {
            report.push_str("   Assessment: âœ… GOOD accuracy\n");
        } else if metric.final_reprojection_error < 0.1 {
            report.push_str("   Assessment: âš ï¸  ACCEPTABLE accuracy\n");
        } else {
            report.push_str("   Assessment: âŒ POOR accuracy - needs investigation\n");
        }
        report.push_str("\n");
    }

    // Summary statistics
    report.push_str("SUMMARY STATISTICS:\n");
    report.push_str("==================\n\n");

    let avg_time = total_time / metrics.len() as f64;
    let best_accuracy = metrics.iter().map(|m| m.final_reprojection_error).fold(f64::INFINITY, f64::min);
    let worst_accuracy = metrics.iter().map(|m| m.final_reprojection_error).fold(0.0, f64::max);
    let fastest_time = metrics.iter().map(|m| m.optimization_time_ms).fold(f64::INFINITY, f64::min);
    let slowest_time = metrics.iter().map(|m| m.optimization_time_ms).fold(0.0, f64::max);

    report.push_str(&format!("Total Conversions: {}\n", metrics.len()));
    report.push_str(&format!("Average Reprojection Error: {:.6} pixels\n", avg_error));
    report.push_str(&format!("Best Accuracy: {:.6} pixels\n", best_accuracy));
    report.push_str(&format!("Worst Accuracy: {:.6} pixels\n", worst_accuracy));
    report.push_str(&format!("Average Optimization Time: {:.2} ms\n", avg_time));
    report.push_str(&format!("Total Optimization Time: {:.2} ms\n", total_time));
    report.push_str(&format!("Fastest Conversion: {:.2} ms\n", fastest_time));
    report.push_str(&format!("Slowest Conversion: {:.2} ms\n", slowest_time));

    // Find best and worst performers
    let best_model = metrics.iter().min_by(|a, b| a.final_reprojection_error.partial_cmp(&b.final_reprojection_error).unwrap()).unwrap();
    let fastest_model = metrics.iter().min_by(|a, b| a.optimization_time_ms.partial_cmp(&b.optimization_time_ms).unwrap()).unwrap();

    report.push_str(&format!("Best Accuracy Model: {} ({:.6} pixels)\n", best_model.model_name, best_model.final_reprojection_error));
    report.push_str(&format!("Fastest Model: {} ({:.2} ms)\n", fastest_model.model_name, fastest_model.optimization_time_ms));

    // Technical details
    report.push_str("\nTECHNICAL IMPLEMENTATION:\n");
    report.push_str("========================\n\n");
    report.push_str("âœ… Optimization Framework: factrs (Rust)\n");
    report.push_str("âœ… Jacobian Computation: Analytical derivatives\n");
    report.push_str("âœ… Residual Formulation: C++ compatible analytical form\n");
    report.push_str("âœ… Parameter Bounds: Enforced (e.g., Alpha âˆˆ (0, 1])\n");
    report.push_str("âœ… Convergence Criteria: Automatic termination\n");
    report.push_str("âœ… Test Data: Deterministic generation (fixed seed)\n");

    // Overall assessment
    report.push_str("\nOVERALL ASSESSMENT:\n");
    report.push_str("==================\n\n");

    if avg_error < 0.001 {
        report.push_str("ğŸ† EXCELLENT: Average reprojection error < 0.001 pixels\n");
        report.push_str("   All conversions achieve sub-millipixel accuracy.\n");
    } else if avg_error < 0.01 {
        report.push_str("âœ… GOOD: Average reprojection error < 0.01 pixels\n");
        report.push_str("   Conversions achieve good accuracy for most applications.\n");
    } else if avg_error < 0.1 {
        report.push_str("âš ï¸  ACCEPTABLE: Average reprojection error < 0.1 pixels\n");
        report.push_str("   Accuracy acceptable but some models may need refinement.\n");
    } else {
        report.push_str("âŒ POOR: Average reprojection error > 0.1 pixels\n");
        report.push_str("   Significant accuracy issues detected - requires investigation.\n");
    }

    // Write to file
    std::fs::write("rust_benchmark_results.txt", report)?;
    println!("ğŸ“„ Rust benchmark results exported to: rust_benchmark_results.txt");

    Ok(())
}
